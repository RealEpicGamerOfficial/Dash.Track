<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Dash.Track v4.0 - Minimal Console</title>
    <!-- Load TensorFlow.js and COCO-SSD for Object Detection -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
    <!-- Load Tailwind CSS -->
    <script src="https://cdn.tailwindcss.com"></script>
    <!-- Load Google Material Symbols (Filled, for high-contrast) -->
    <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
    
    <style>
        /* Modern Dark Theme Aesthetic */
        body {
            background-color: #0d1117; /* GitHub Dark Mode / VS Code Dark */
        }
        .ui-card {
            background-color: #161b22; /* Darker Card background */
            border: 1px solid #30363d;
            border-radius: 0.75rem;
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.5);
        }
        /* Primary Accent Color: Cyan/Teal */
        .accent-primary { color: #2dd4bf; } 

        .camera-container {
            position: relative;
            width: 100%;
            height: 100%;
            border-radius: 1rem;
            overflow: hidden;
            box-shadow: 0 0 20px rgba(45, 212, 191, 0.3); /* Soft cyan glow */
            border: 2px solid #2dd4bf;
        }
        
        /* Fullscreen handling for the container when the document is fullscreen */
        .camera-container:fullscreen {
            /* This section is now unused because fullscreen targets the document, 
               but we keep video/canvas styling for clean display. */
        }
        
        #webcamVideo { display: none; }
        #outputCanvas {
            display: block;
            width: 100%;
            height: auto;
            background-color: #000;
        }
        
        /* Primary Button Style (Teal/Cyan) */
        .btn-primary {
            background-color: #2dd4bf;
            color: #0d1117;
            font-weight: 700;
            transition: all 0.2s;
        }
        .btn-primary:hover:not(:disabled) {
            background-color: #14b8a6;
            transform: translateY(-1px);
        }
        .btn-primary:active:not(:disabled) {
            transform: scale(0.98);
        }
        
        /* Toggle Button Style */
        .btn-toggle {
            background-color: #1a1b24;
            border: 1px solid #30363d;
            color: #cbd5e1; /* Increased contrast for inactive text */
        }
        .btn-toggle.active {
            background-color: #2dd4bf; /* Cyan-400 */
            color: #0d1117; 
            border-color: #2dd4bf;
            box-shadow: 0 0 10px rgba(45, 212, 191, 0.5);
        }

        /* Slider Thumb/Track */
        .range-slider {
            -webkit-appearance: none;
            appearance: none;
            height: 6px;
            background: #30363d;
            border-radius: 3px;
            cursor: pointer;
        }
        .range-slider::-webkit-slider-thumb {
            -webkit-appearance: none;
            appearance: none;
            width: 16px;
            height: 16px;
            background: #2dd4bf; 
            border-radius: 50%;
            border: 3px solid #0d1117;
            box-shadow: 0 0 5px rgba(45, 212, 191, 0.7);
        }
    </style>
    <script>
        tailwind.config = {
            theme: {
                extend: {
                    fontFamily: {
                        sans: ['Inter', 'sans-serif'],
                    },
                    colors: {
                        'primary-cyan': '#2dd4bf',
                    }
                }
            }
        }
    </script>
</head>
<body class="text-white min-h-screen p-4 sm:p-8 font-sans">

    <!-- Warning Modal (Cleaner Look) -->
    <div id="warningModal" class="fixed inset-0 z-50 flex items-center justify-center bg-gray-900 bg-opacity-95 backdrop-blur-sm">
        <div class="ui-card p-8 rounded-xl max-w-lg w-full border-t-4 border-primary-cyan transition-all">
            <h2 class="text-3xl font-extrabold accent-primary mb-4 flex items-center">
                <span class="material-icons text-4xl mr-3">verified_user</span>
                SYSTEM PROTOCOL AGREEMENT
            </h2>
            <p class="text-gray-400 leading-relaxed mb-6 text-sm">
                This application is a local GameCo. Experiment. All AI processing (TensorFlow.js) runs entirely in your browser. **No video data is transmitted externally.** These systems are experimental and intended for disruptive research.
            </p>
            <button onclick="document.getElementById('warningModal').classList.add('hidden')" class="w-full py-3 btn-primary rounded-lg shadow-lg">
                ACKNOWLEDGE & START
            </button>
        </div>
    </div>

    <!-- MAIN DASHBOARD LAYOUT -->
    <div class="max-w-7xl mx-auto">
        <!-- HEADER / BRANDING -->
        <header class="mb-8 border-b border-gray-700 pb-4">
            <h1 class="text-4xl font-extrabold text-center text-transparent bg-clip-text bg-gradient-to-r from-primary-cyan to-blue-400 tracking-wider">
                DASH.<span class="text-primary-cyan">TRACK</span> V4.0
            </h1>
            <p class="text-center text-gray-500 text-xs font-mono uppercase mt-1">
                Real-Time Detection Console
            </p>
        </header>
        
        <!-- TWO-COLUMN CONTENT GRID -->
        <div class="grid lg:grid-cols-3 gap-8">
            
            <!-- LEFT COLUMN: VIDEO FEED -->
            <div class="lg:col-span-2 space-y-4">
                
                <!-- Camera Container -->
                <div class="camera-container aspect-video">
                    <video id="webcamVideo" autoplay playsinline muted></video>
                    <canvas id="outputCanvas" width="800" height="450"></canvas>
                </div>

                <!-- MAIN POWER CONTROLS -->
                <div class="grid grid-cols-2 gap-4">
                    <button id="startButton" onclick="startCamera()" class="py-4 btn-primary rounded-lg text-lg flex items-center justify-center disabled:opacity-50" disabled>
                        <span class="material-icons text-3xl mr-2">camera_indoor</span>
                        POWER ON
                    </button>
                    <button id="stopButton" onclick="stopCamera()" class="py-4 bg-gray-700 hover:bg-red-600 text-red-300 font-semibold rounded-lg text-lg flex items-center justify-center disabled:opacity-50 disabled:hover:bg-gray-700" disabled>
                        <span class="material-icons text-3xl mr-2">power_off</span>
                        SHUT DOWN
                    </button>
                </div>
            </div>

            <!-- RIGHT COLUMN: CONTROL PANEL -->
            <div class="lg:col-span-1 space-y-6">

                <!-- 1. CORE TOGGLES CARD -->
                <div class="ui-card p-4 space-y-4">
                    <h2 class="text-xl font-bold border-b border-gray-700 pb-2 flex items-center accent-primary">
                        <span class="material-icons mr-2 text-xl">tune</span> System Core Toggles
                    </h2>
                    
                    <div class="grid grid-cols-2 gap-3">
                        <!-- Mode Toggle -->
                        <button id="modeToggle" onclick="toggleMode()" class="p-3 btn-toggle active rounded-lg text-sm flex flex-col items-center disabled:opacity-50" disabled>
                            <span class="material-icons text-3xl mb-1" id="modeIcon">filter_b_and_w</span>
                            <span id="modeText" class="font-semibold">Depth Map</span>
                        </button>
                        
                        <!-- AI Model Selector -->
                        <button id="aiDetectionToggle" onclick="toggleAIDetectionMode()" class="p-3 btn-toggle active rounded-lg text-sm flex flex-col items-center disabled:opacity-50" disabled>
                            <span class="material-icons text-3xl mb-1 text-yellow-400" id="aiIcon">model_training</span>
                            <span id="aiText" class="font-semibold"><span class="font-semibold text-yellow-400">AI Detection: V1</span></span>
                        </button>
                    </div>
                </div>

                <!-- 2. FINE-TUNING SLIDERS CARD -->
                <div class="ui-card p-4 space-y-4">
                    <h2 class="text-xl font-bold border-b border-gray-700 pb-2 flex items-center accent-primary">
                        <span class="material-icons mr-2 text-xl">straighten</span> Fine-Tuning Console
                    </h2>
                    <!-- Sensitivity Slider -->
                    <div>
                        <label for="sensitivity" class="block text-sm font-semibold text-gray-400 flex justify-between">
                            Edge Sensitivity Multiplier
                            <span id="sensitivityValue" class="font-mono text-primary-cyan">1.5x</span>
                        </label>
                        <input type="range" id="sensitivity" min="0.5" max="4.0" step="0.1" value="1.5" oninput="updateSensitivity(this.value)" class="w-full mt-2 range-slider">
                    </div>
                </div>

                <!-- 3. UTILITY CONTROLS CARD -->
                <div class="ui-card p-4 space-y-4">
                    <h2 class="text-xl font-bold border-b border-gray-700 pb-2 flex items-center accent-primary">
                        <span class="material-icons mr-2 text-xl">storage</span> Data Management
                    </h2>
                    <div class="grid grid-cols-2 gap-3">
                         <!-- RTD Recording Button -->
                        <button id="recordButton" onclick="toggleRecording()" class="py-2 bg-gray-700 hover:bg-red-700 transition duration-300 text-white font-semibold rounded-lg shadow-inner flex items-center justify-center text-sm disabled:opacity-50" disabled>
                            <span class="material-icons text-xl mr-1" id="recordIcon">videocam_off</span>
                            <span id="recordText">Start RTD Record</span>
                        </button>
                        <!-- Fullscreen Button -->
                        <button id="fullscreenButton" onclick="requestFullscreen()" class="py-2 bg-gray-700 hover:bg-gray-600 transition duration-300 text-white font-semibold rounded-lg shadow-inner flex items-center justify-center text-sm disabled:opacity-50" disabled>
                            <span class="material-icons text-xl mr-1">fullscreen</span>
                            Maximize View
                        </button>
                    </div>
                </div>
            </div>
        </div>
    </div>
    
    <!-- Firebase Initialization Script -->
    <script type="module">
        import { initializeApp } from "https://www.gstatic.com/firebasejs/11.6.1/firebase-app.js";
        import { getAuth, signInAnonymously, signInWithCustomToken, onAuthStateChanged, setPersistence, browserSessionPersistence } from "https://www.gstatic.com/firebasejs/11.6.1/firebase-auth.js";
        import { getFirestore, setLogLevel } from "https://www.gstatic.com/firebasejs/11.6.1/firebase-firestore.js";

        // --- Global Firebase Configuration (MANDATORY) ---
        const appId = typeof __app_id !== 'undefined' ? __app_id : 'default-app-id';
        const firebaseConfig = JSON.parse(typeof __firebase_config !== 'undefined' ? __firebase_config : '{}');
        const initialAuthToken = typeof __initial_auth_token !== 'undefined' ? __initial_auth_token : null;
        
        let app;
        let auth;
        let db;
        let userId = null;

        async function initializeFirebase() {
            if (Object.keys(firebaseConfig).length === 0) {
                console.error("Firebase config is empty. Cannot initialize.");
                return;
            }

            try {
                app = initializeApp(firebaseConfig);
                auth = getAuth(app);
                db = getFirestore(app);
                setLogLevel('error'); 

                await setPersistence(auth, browserSessionPersistence);

                await new Promise((resolve) => {
                    const unsubscribe = onAuthStateChanged(auth, async (user) => {
                        unsubscribe(); 
                        if (user) {
                            userId = user.uid;
                            resolve();
                        } else {
                            try {
                                if (initialAuthToken) {
                                    const userCredential = await signInWithCustomToken(auth, initialAuthToken);
                                    userId = userCredential.user.uid;
                                } else {
                                    const userCredential = await signInAnonymously(auth);
                                    userId = userCredential.user.uid;
                                }
                                resolve();
                            } catch (error) {
                                console.error("Firebase Sign-In Error:", error);
                                // Continue initialization even if sign-in fails
                                resolve();
                            }
                        }
                    });
                });
            } catch (error) {
                console.error("Firebase Initialization Failed:", error);
            }
        }
        
        // Run Firebase initialization
        initializeFirebase();
    </script>
    
    <!-- Application Logic Script -->
    <script>
        // --- DOM Elements ---
        const video = document.getElementById('webcamVideo');
        const canvas = document.getElementById('outputCanvas');
        const ctx = canvas.getContext('2d');
        const startButton = document.getElementById('startButton');
        const stopButton = document.getElementById('stopButton');
        const modeToggle = document.getElementById('modeToggle');
        const modeIcon = document.getElementById('modeIcon');
        const modeText = document.getElementById('modeText');
        const fullscreenButton = document.getElementById('fullscreenButton');
        const sensitivityInput = document.getElementById('sensitivity');
        const sensitivityValueSpan = document.getElementById('sensitivityValue');
        const recordButton = document.getElementById('recordButton');
        const recordIcon = document.getElementById('recordIcon');
        const recordText = document.getElementById('recordText');
        const aiDetectionToggle = document.getElementById('aiDetectionToggle');
        const aiIcon = document.getElementById('aiIcon');
        const aiText = document.getElementById('aiText');

        // --- State Variables ---
        let animationFrameId;
        let stream;
        let showProcessedMap = true;
        let edgeSensitivity = 1.5; 
        let detectionModel = null;
        let detections = [];
        let currentDetectionMode = 'V1'; // 'V1', 'V2', 'OFF'
        let detectionInterval = 500; // Default V1
        let detectionThreshold = 0.6; // Default V1
        let lastDetectionTime = 0;
        
        // Recording State
        let isRecording = false;
        let mediaRecorder;
        let recordedChunks = [];
        
        // --- Kernels ---
        const sobelX = [ [-1, 0, 1], [-2, 0, 2], [-1, 0, 1] ];
        const sobelY = [ [-1, -2, -1], [0, 0, 0], [1, 2, 1] ];
        const gaussianKernel = [ [1, 2, 1], [2, 4, 2], [1, 2, 1] ];
        const kernelSum = 16;
        
        // --- Model and Mode Functions ---

        async function loadDetectionModel() {
            console.log('[SYS] Loading ML Module...');
            try {
                await tf.ready(); 
                detectionModel = await cocoSsd.load();
                
                setDetectionMode('V1'); 

                console.log('[SYS] Module online. Ready for Power On.');
                startButton.disabled = false;
            } catch (error) {
                console.error("[ERR] Model load failed. Check console.", error);
            }
        }
        
        function setDetectionMode(mode) {
            currentDetectionMode = mode;
            aiDetectionToggle.classList.remove('active');
            aiIcon.classList.remove('text-red-400', 'text-green-400', 'text-yellow-400');
            
            let iconText = '';
            let color = '';
            let isActive = true;

            switch (mode) {
                case 'V1':
                    detectionInterval = 500; 
                    detectionThreshold = 0.6;
                    iconText = 'AI Detection: V1';
                    color = 'text-yellow-400';
                    break;
                case 'V2':
                    detectionInterval = 750; 
                    detectionThreshold = 0.8;
                    iconText = 'AI Detection: V2 (Pico-Pro)'; 
                    color = 'text-primary-cyan'; // Changed to primary-cyan/teal for V2
                    break;
                case 'OFF':
                    detectionInterval = Infinity; 
                    detectionThreshold = 1.0;
                    detections = []; 
                    iconText = 'AI Detection: OFF';
                    color = 'text-red-400';
                    isActive = false;
                    break;
            }
            
            aiText.innerHTML = `<span class="font-semibold ${color}">${iconText}</span>`;
            aiIcon.classList.add(color);
            aiDetectionToggle.classList.toggle('active', isActive);
            console.log(`[SYS] AI Detection set to ${mode}.`);
        }

        window.toggleAIDetectionMode = function() {
            switch (currentDetectionMode) {
                case 'V1':
                    setDetectionMode('V2');
                    break;
                case 'V2':
                    setDetectionMode('OFF');
                    break;
                case 'OFF':
                default:
                    setDetectionMode('V1');
                    break;
            }
        }


        // --- Controls and Interaction Functions ---

        window.requestFullscreen = function() {
            // --- USER REQUEST: Target the entire document for fullscreen ---
            const docEl = document.documentElement;
            if (docEl.requestFullscreen) {
                docEl.requestFullscreen();
            } else if (docEl.webkitRequestFullscreen) {
                docEl.webkitRequestFullscreen();
            } else if (docEl.msRequestFullscreen) {
                docEl.msRequestFullscreen();
            }
            // --- END USER REQUEST ---
        }

        function handleFullscreenChange() {
            const isFullscreen = document.fullscreenElement || document.webkitFullscreenElement;
            console.log(`[SYS] Fullscreen Toggled: ${isFullscreen ? 'Engaged' : 'Disengaged'}`);
        }
        document.addEventListener('fullscreenchange', handleFullscreenChange);
        document.addEventListener('webkitfullscreenchange', handleFullscreenChange);
        
        window.updateSensitivity = function(value) {
            edgeSensitivity = parseFloat(value);
            sensitivityValueSpan.textContent = edgeSensitivity.toFixed(1) + 'x';
        }

        window.toggleMode = function() {
            showProcessedMap = !showProcessedMap;
            modeToggle.classList.toggle('active', showProcessedMap);
            
            if (showProcessedMap) {
                modeIcon.textContent = 'filter_b_and_w';
                modeText.textContent = 'Depth Map';
            } else {
                modeIcon.textContent = 'photo_camera'; 
                modeText.textContent = 'Live Video';
            }
        }
        
        // --- RTD Recording ---
        
        window.toggleRecording = function() {
            if (isRecording) {
                stopRecording();
            } else {
                startRecording();
            }
        }

        function startRecording() {
            if (!stream || isRecording) return;
            
            isRecording = true;
            recordedChunks = [];

            // Capture the content of the CANVAS (the processed feed)
            const canvasStream = canvas.captureStream(30); 
            mediaRecorder = new MediaRecorder(canvasStream, { mimeType: 'video/webm; codecs=vp8' });

            mediaRecorder.ondataavailable = (event) => {
                if (event.data.size > 0) {
                    recordedChunks.push(event.data);
                }
            };

            mediaRecorder.onstop = () => {
                const blob = new Blob(recordedChunks, { type: 'video/webm' });
                const url = URL.createObjectURL(blob);
                const a = document.createElement('a');
                a.style.display = 'none';
                a.href = url;
                a.download = `DashTrack_RTD_${new Date().toISOString()}.webm`;
                document.body.appendChild(a);
                a.click();
                window.URL.revokeObjectURL(url);
                
                console.log(`[SYS] RTD Recording Saved and Downloaded.`);
            };

            mediaRecorder.start();

            // UI Update
            recordIcon.textContent = 'videocam';
            recordButton.classList.remove('bg-gray-700', 'hover:bg-red-700');
            recordButton.classList.add('bg-red-600', 'hover:bg-red-500', 'active');
            recordText.textContent = 'Stop RTD Record';
            console.log('[SYS] RTD Recording started.');
        }

        function stopRecording() {
            if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                mediaRecorder.stop();
            }
            isRecording = false;

            // UI Update
            recordIcon.textContent = 'videocam_off';
            recordButton.classList.remove('bg-red-600', 'hover:bg-red-500', 'active');
            recordButton.classList.add('bg-gray-700', 'hover:bg-red-700');
            recordText.textContent = 'Start RTD Record';
            console.log('[SYS] RTD Recording finalizing. Preparing download...');
        }
        
        // --- Core Application Logic ---

        window.startCamera = function() {
            if (stream) { stopCamera(); }

            console.log('[SYS] Requesting Stream Access...');
            startButton.disabled = true;

            navigator.mediaDevices.getUserMedia({ 
                video: { 
                    facingMode: 'user',
                    aspectRatio: { ideal: 1.7777 }, 
                    width: { ideal: 1280 },
                    height: { ideal: 720 }
                } 
            })
            .then(mediaStream => {
                stream = mediaStream;
                video.srcObject = stream;
                video.onloadedmetadata = () => {
                    // Set canvas drawing buffer to video resolution
                    canvas.width = video.videoWidth;
                    canvas.height = video.videoHeight;
                    video.play();
                    
                    console.log(`[SYS] Dash.Track Active. Resolution: ${canvas.width}x${canvas.height}.`);
                    stopButton.disabled = false;
                    modeToggle.disabled = false;
                    fullscreenButton.disabled = false;
                    recordButton.disabled = false;
                    aiDetectionToggle.disabled = false; 
                    
                    requestAnimationFrame(processFrame);
                    // Initial detection run (non-blocking)
                    runObjectDetection(); 
                };
            })
            .catch(err => {
                console.error("[ERR] Access Denied: Check browser permissions.", err);
                startButton.disabled = false;
            });
        }

        window.stopCamera = function() {
            if (animationFrameId) {
                cancelAnimationFrame(animationFrameId);
                animationFrameId = null;
            }
            if (isRecording) {
                stopRecording();
            }
            if (stream) {
                stream.getTracks().forEach(track => track.stop());
                stream = null;
                video.srcObject = null;
            }
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            console.log('[SYS] Power Down Complete. System Offline.');
            
            startButton.disabled = false;
            stopButton.disabled = true;
            modeToggle.disabled = true;
            fullscreenButton.disabled = true;
            recordButton.disabled = true;
            aiDetectionToggle.disabled = true; 
            detections = [];
            
            // Reset state and UI toggles
            showProcessedMap = true;
            setDetectionMode('V1'); 
            modeToggle.classList.remove('active');
            modeIcon.textContent = 'filter_b_and_w';
            modeText.textContent = 'Depth Map';
        }

        async function runObjectDetection() {
            if (currentDetectionMode === 'OFF' || !detectionModel) {
                detections = [];
                return;
            }
            
            const now = performance.now();
            if (now - lastDetectionTime < detectionInterval) {
                return;
            }
            lastDetectionTime = now;
            
            try {
                const rawDetections = await detectionModel.detect(video);
                detections = rawDetections.filter(p => p.score >= detectionThreshold);
                
            } catch (error) {
                console.error("Detection error:", error);
                detections = [];
            }
        }
        
        function processFrame(time) {
            if (!video.paused && !video.ended) {
                
                ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
                
                if (showProcessedMap) {
                    applyPseudoDepthFilter();
                }

                drawDetections();
            }
            
            runObjectDetection();
            animationFrameId = requestAnimationFrame(processFrame);
        }

        // --- Image Processing Functions ---

        function applyGaussianBlur(grayData, width, height) {
            const blurredData = new Array(width * height).fill(0);
            for (let y = 1; y < height - 1; y++) {
                for (let x = 1; x < width - 1; x++) {
                    let sum = 0;
                    for (let ky = -1; ky <= 1; ky++) {
                        for (let kx = -1; kx <= 1; kx++) {
                            const pixelIndex = (y + ky) * width + (x + kx);
                            const kernelValue = gaussianKernel[ky + 1][kx + 1];
                            sum += grayData[pixelIndex] * kernelValue;
                        }
                    }
                    blurredData[y * width + x] = sum / kernelSum;
                }
            }
            for (let i = 0; i < width; i++) {
                blurredData[i] = grayData[i]; 
                blurredData[(height - 1) * width + i] = grayData[(height - 1) * width + i];
            }
            for (let j = 0; j < height; j++) {
                blurredData[j * width] = grayData[j * width]; 
                blurredData[j * width + width - 1] = grayData[j * width + width - 1];
            }
            return blurredData;
        }

        function applyPseudoDepthFilter() {
            let imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
            let data = imageData.data;
            const width = canvas.width;
            const height = canvas.height;
            
            const grayData = new Array(width * height);

            for (let i = 0; i < data.length; i += 4) {
                let r = data[i];
                let g = data[i + 1];
                let b = data[i + 2];
                
                const gray = 0.2126 * r + 0.7152 * g + 0.0722 * b;
                grayData[i / 4] = gray;
            }

            const blurredGrayData = applyGaussianBlur(grayData, width, height);

            for (let y = 1; y < height - 1; y++) {
                for (let x = 1; x < width - 1; x++) {
                    const i = y * width + x;
                    
                    let Gx = 0;
                    let Gy = 0;

                    for (let ky = -1; ky <= 1; ky++) {
                        for (let kx = -1; kx <= 1; kx++) {
                            const pixelIndex = (y + ky) * width + (x + kx);
                            const kernelXValue = sobelX[ky + 1][kx + 1];
                            const kernelYValue = sobelY[ky + 1][kx + 1];
                            const blurredGrayValue = blurredGrayData[pixelIndex];

                            Gx += blurredGrayValue * kernelXValue;
                            Gy += blurredGrayValue * kernelYValue;
                        }
                    }

                    const magnitude = Math.sqrt(Gx * Gx + Gy * Gy);
                    const edgeStrength = Math.min(255, Math.max(0, magnitude * edgeSensitivity)); 

                    let r, g, b;
                    const t = edgeStrength / 255.0; 

                    // Color mapping: Blue (far/weak edge) to Red (near/strong edge)
                    if (t < 0.5) {
                        r = 0;
                        g = Math.floor(t * 2 * 255);
                        b = Math.floor(255 - t * 2 * 255);
                    } else {
                        r = Math.floor((t - 0.5) * 2 * 255);
                        g = Math.floor(255 - (t - 0.5) * 2 * 255);
                        b = 0;
                    }

                    const dataIndex = i * 4;
                    data[dataIndex] = r;
                    data[dataIndex + 1] = g;
                    data[dataIndex + 2] = b;
                }
            }

            ctx.putImageData(imageData, 0, 0);
        }

        // --- Detection Drawing Functions ---

        function drawRigSkeleton(x, y, width, height) {
            // Rig drawing only for V1
            if (currentDetectionMode !== 'V1') return; 

            // V4.0 Rig Color: Bright Cyan
            ctx.strokeStyle = '#2dd4bf'; 
            ctx.fillStyle = '#67e8f9'; 
            ctx.lineWidth = 3; 
            ctx.shadowBlur = 0; 

            const jointRadius = Math.max(3, Math.min(7, height * 0.007)); 

            const p = (relX, relY) => ({
                x: x + width * relX,
                y: y + height * relY
            });

            const points = {
                nose: p(0.5, 0.05), leftEye: p(0.45, 0.05), rightEye: p(0.55, 0.05),
                leftEar: p(0.35, 0.1), rightEar: p(0.65, 0.1),
                leftShoulder: p(0.3, 0.25), rightShoulder: p(0.7, 0.25),
                leftHip: p(0.4, 0.6), rightHip: p(0.6, 0.6),
                leftElbow: p(0.2, 0.45), rightElbow: p(0.8, 0.45),
                leftWrist: p(0.1, 0.7), rightWrist: p(0.9, 0.7),
                leftKnee: p(0.4, 0.8), rightKnee: p(0.6, 0.8),
                leftAnkle: p(0.4, 0.95), rightAnkle: p(0.6, 0.95),
            };

            const connections = [
                [points.leftEye, points.nose], [points.rightEye, points.nose],
                [points.leftEar, points.leftShoulder], [points.rightEar, points.rightShoulder],
                [points.leftShoulder, points.rightShoulder], [points.leftShoulder, points.leftHip],
                [points.rightShoulder, points.rightHip], [points.leftHip, points.rightHip],
                [points.leftShoulder, points.leftElbow], [points.leftElbow, points.leftWrist],
                [points.rightShoulder, points.rightElbow], [points.rightElbow, points.rightWrist],
                [points.leftHip, points.leftKnee], [points.leftKnee, points.leftAnkle],
                [points.rightHip, points.rightKnee], [points.rightKnee, points.rightAnkle],
            ];
            
            ctx.beginPath();
            connections.forEach(([p1, p2]) => { ctx.moveTo(p1.x, p1.y); ctx.lineTo(p2.x, p2.y); });
            ctx.stroke();

            Object.values(points).forEach(p => {
                ctx.beginPath();
                ctx.arc(p.x, p.y, jointRadius, 0, 2 * Math.PI);
                ctx.fill();
            });
        }


        function drawDetections() {
            ctx.lineWidth = 2;
            ctx.font = '14px Inter, sans-serif';
            ctx.shadowBlur = 5;

            detections.forEach(prediction => {
                const [x, y, width, height] = prediction.bbox;
                const score = (prediction.score * 100).toFixed(1);
                const label = `${prediction.class} (${score}%)`;
                
                let boxColor;

                if (prediction.class === 'person') {
                    // V2 gets the primary-cyan color (Pico-Pro, high precision, no rig)
                    boxColor = currentDetectionMode === 'V2' ? '#2dd4bf' : '#fcd34d'; // V1 is yellow
                    
                    if (currentDetectionMode === 'V1') {
                        drawRigSkeleton(x, y, width, height); 
                    }

                } else if (prediction.class === 'cell phone' || prediction.class === 'laptop') {
                    boxColor = '#f59e0b'; // Amber for devices
                } else {
                    boxColor = '#a78bfa'; // Violet for general objects
                }
                
                ctx.strokeStyle = boxColor; 
                ctx.fillStyle = boxColor;
                
                ctx.shadowColor = boxColor; 
                ctx.strokeRect(x, y, width, height);

                const textWidth = ctx.measureText(label).width;
                const textHeight = 18; 
                
                // Draw opaque background for label
                ctx.save();
                ctx.fillStyle = boxColor;
                ctx.fillRect(x, y, textWidth + 10, textHeight + 4);
                ctx.restore();

                // Draw Label Text
                ctx.fillStyle = '#0d1117'; // Text inside label box is dark
                ctx.shadowBlur = 0;
                ctx.fillText(label, x + 5, y + textHeight - 2);
            });
        }

        // Initial setup
        document.addEventListener('DOMContentLoaded', () => {
            loadDetectionModel();
            updateSensitivity(sensitivityInput.value);
            window.addEventListener('beforeunload', stopCamera);
            // Initialize mode button visually
            modeToggle.classList.toggle('active', showProcessedMap);
        });

    </script>
</body>
</html>
