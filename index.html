<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Dash.Track v4.0 - Minimal Console</title>
    <!-- Load TensorFlow.js and COCO-SSD for Object Detection -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
    <!-- Load Tailwind CSS -->
    <script src="https://cdn.tailwindcss.com"></script>
    <!-- Load Google Material Symbols (Filled, for high-contrast) -->
    <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
    
    <style>
        /* Modern Dark Theme Aesthetic */
        body {
            background-color: #0d1117; /* GitHub Dark Mode / VS Code Dark */
        }
        .ui-card {
            background-color: rgba(22, 27, 34, 0.75); /* #161b22 with 75% opacity */
            backdrop-filter: blur(12px);
            border: 1px solid #30363d;
            border-radius: 0.75rem;
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.5);
            /* Add consistent top border and transition */
            border-top: 4px solid #2dd4bf; 
            transition: all 0.3s ease;
        }
        .ui-card:hover {
            box-shadow: 0 8px 24px rgba(45, 212, 191, 0.2); /* Faint cyan glow on hover */
        }
        /* Primary Accent Color: Cyan/Teal */
        .accent-primary { color: #2dd4bf; } 

        .camera-container {
            position: relative;
            width: 100%;
            height: 100%;
            border-radius: 1rem;
            overflow: hidden;
            box-shadow: 0 0 20px rgba(45, 212, 191, 0.3); /* Soft cyan glow */
            border: 2px solid #2dd4bf;
        }
        
        /* Fullscreen handling for the container when the document is fullscreen */
        .camera-container:fullscreen {
            /* This section is now unused because fullscreen targets the document, 
               but we keep video/canvas styling for clean display. */
        }
        
        #webcamVideo { display: none; }
        #outputCanvas {
            display: block;
            width: 100%;
            height: auto;
            background-color: #000;
        }
        
        /* Primary Button Style (Teal/Cyan) */
        .btn-primary {
            background-color: #2dd4bf;
            color: #0d1117;
            font-weight: 700;
            transition: all 0.2s;
        }
        .btn-primary:hover:not(:disabled) {
            background-color: #14b8a6;
            transform: translateY(-1px);
        }
        .btn-primary:active:not(:disabled) {
            transform: scale(0.98);
        }
        
        /* Toggle Button Style */
        .btn-toggle {
            background-color: #1a1b24;
            border: 1px solid #30363d;
            color: #cbd5e1; /* Increased contrast for inactive text */
            transition: all 0.2s ease;
        }
        .btn-toggle.active {
            background-color: #2dd4bf; /* Cyan-400 */
            color: #0d1117; 
            border-color: #2dd4bf;
            box-shadow: 0 0 10px rgba(45, 212, 191, 0.5);
        }

        /* Redesign Styles for Toggles */
        .segmented-btn-active {
            background-color: #2dd4bf; 
            color: #0d1117;
            box-shadow: 0 2px 8px rgba(45, 212, 191, 0.3);
            font-weight: 700;
        }
        .segmented-btn-inactive {
            color: #9ca3af; /* Gray-400 */
            background-color: transparent;
        }

        /* AI Detection Button Colors based on state (managed by JS) */
        .ai-v1 { background-color: #d97706; color: #fff; box-shadow: 0 0 10px rgba(245, 158, 11, 0.5); } /* Amber */
        .ai-v2 { background-color: #2dd4bf; color: #0d1117; box-shadow: 0 0 10px rgba(45, 212, 191, 0.5); } /* Cyan */
        .ai-off { background-color: #ef4444; color: #fff; box-shadow: 0 0 10px rgba(239, 68, 68, 0.5); } /* Red */


        /* Slider Thumb/Track */
        .range-slider {
            -webkit-appearance: none;
            appearance: none;
            height: 6px;
            background: #30363d;
            border-radius: 3px;
            cursor: pointer;
        }
        .range-slider::-webkit-slider-thumb {
            -webkit-appearance: none;
            appearance: none;
            width: 16px;
            height: 16px;
            background: #2dd4bf; 
            border-radius: 50%;
            border: 3px solid #0d1117;
            box-shadow: 0 0 5px rgba(45, 212, 191, 0.7);
        }
    </style>
    <script>
        tailwind.config = {
            theme: {
                extend: {
                    fontFamily: {
                        sans: ['Inter', 'sans-serif'],
                    },
                    colors: {
                        'primary-cyan': '#2dd4bf',
                    }
                }
            }
        }
    </script>
</head>
<body class="text-white min-h-screen p-4 sm:p-8 font-sans">

    <!-- Warning Modal (Cleaner Look) -->
    <div id="warningModal" class="fixed inset-0 z-50 flex items-center justify-center bg-gray-900 bg-opacity-95 backdrop-blur-sm">
        <div class="ui-card p-8 rounded-xl max-w-lg w-full border-t-4 border-primary-cyan transition-all">
            <h2 class="text-3xl font-extrabold accent-primary mb-4 flex items-center">
                <span class="material-icons text-4xl mr-3">verified_user</span>
                SYSTEM PROTOCOL AGREEMENT
            </h2>
            <p class="text-gray-400 leading-relaxed mb-6 text-sm">
                This application is a local GameCo. Experiment. All AI processing (TensorFlow.js) runs entirely in your browser. **No video data is transmitted externally.** These systems are experimental and intended for disruptive research.
            </p>
            <button onclick="document.getElementById('warningModal').classList.add('hidden')" class="w-full py-3 btn-primary rounded-lg shadow-lg">
                ACKNOWLEDGE & START
            </button>
        </div>
    </div>

    <!-- MAIN DASHBOARD LAYOUT -->
    <div class="max-w-7xl mx-auto">
        <!-- HEADER / BRANDING -->
        <header class="mb-8 border-b border-gray-700 pb-4">
            <h1 class="text-4xl font-extrabold text-center text-transparent bg-clip-text bg-gradient-to-r from-primary-cyan to-blue-400 tracking-wider">
                DASH.<span class="text-primary-cyan">TRACK</span> V4.0
            </h1>
            <p class="text-center text-gray-500 text-xs font-mono uppercase mt-1">
                Real-Time Detection Console
            </p>
        </header>
        
        <!-- TWO-COLUMN CONTENT GRID -->
        <div class="grid lg:grid-cols-3 gap-8">
            
            <!-- LEFT COLUMN: VIDEO FEED -->
            <div class="lg:col-span-2 space-y-4">
                
                <!-- Camera Container -->
                <div class="camera-container aspect-video">
                    <video id="webcamVideo" autoplay playsinline muted></video>
                    <canvas id="outputCanvas" width="800" height="450"></canvas>
                </div>

                <!-- MAIN POWER CONTROLS -->
                <div class="grid grid-cols-2 gap-4">
                    <button id="startButton" onclick="startCamera()" class="py-4 btn-primary rounded-lg text-lg flex items-center justify-center disabled:opacity-50" disabled>
                        <span class="material-icons text-3xl mr-2">camera_indoor</span>
                        POWER ON
                    </button>
                    <button id="stopButton" onclick="stopCamera()" class="py-4 bg-gray-700 hover:bg-red-600 text-red-300 font-semibold rounded-lg text-lg flex items-center justify-center disabled:opacity-50 disabled:hover:bg-gray-700" disabled>
                        <span class="material-icons text-3xl mr-2">power_off</span>
                        SHUT DOWN
                    </button>
                </div>
            </div>

            <!-- RIGHT COLUMN: CONTROL PANEL -->
            <div class="lg:col-span-1 space-y-6">

                <!-- 1. CORE TOGGLES CARD - REDESIGNED -->
                <div class="ui-card p-6 space-y-5">
                    <h2 class="text-xl font-bold pb-3 flex items-center accent-primary">
                        <span class="material-icons mr-2 text-xl">tune</span> Core System Toggles
                    </h2>
                    
                    <!-- Display Mode Selector (Segmented Control Style) -->
                    <div>
                        <label class="block text-sm font-semibold text-gray-400 mb-2">Display Mode</label>
                        <div id="modeToggleContainer" class="flex p-1 rounded-lg bg-gray-800/50">
                            <!-- Live Video Button -->
                            <button id="modeLiveVideo" onclick="window.setMode(false)" class="flex-1 py-2 text-sm font-semibold rounded-lg transition-colors duration-200 flex items-center justify-center segmented-btn-inactive" disabled>
                                <span class="material-icons text-xl mr-1">photo_camera</span> Live Video
                            </button>
                            <!-- Depth Map Button -->
                            <button id="modeDepthMap" onclick="window.setMode(true)" class="flex-1 py-2 text-sm font-semibold rounded-lg transition-colors duration-200 flex items-center justify-center segmented-btn-active" disabled>
                                <span class="material-icons text-xl mr-1">filter_b_and_w</span> Depth Map
                            </button>
                        </div>
                    </div>

                    <!-- AI Detection Mode (Cycle Button, enhanced) -->
                    <div>
                        <label class="block text-sm font-semibold text-gray-400 mb-2">AI Processing Engine</label>
                        <!-- The class will be updated by JS to ai-v1, ai-v2, or ai-off -->
                        <button id="aiDetectionToggle" onclick="toggleAIDetectionMode()" class="w-full py-3 px-4 rounded-lg text-sm font-bold flex items-center justify-center transition-all duration-200 disabled:opacity-50 ai-v1" disabled>
                            <span class="material-icons text-2xl mr-2" id="aiIcon">model_training</span>
                            <span id="aiText">AI Detection: V1</span>
                        </button>
                    </div>
                </div>

                <!-- 2. FINE-TUNING SLIDERS CARD -->
                <div class="ui-card p-4 space-y-4">
                    <h2 class="text-xl font-bold border-b border-gray-700 pb-2 flex items-center accent-primary">
                        <span class="material-icons mr-2 text-xl">straighten</span> Fine-Tuning Console
                    </h2>
                    <!-- Sensitivity Slider -->
                    <div>
                        <label for="sensitivity" class="block text-sm font-semibold text-gray-400 flex justify-between">
                            Edge Sensitivity Multiplier
                            <span id="sensitivityValue" class="font-mono text-primary-cyan">1.5x</span>
                        </label>
                        <input type="range" id="sensitivity" min="0.5" max="4.0" step="0.1" value="1.5" oninput="updateSensitivity(this.value)" class="w-full mt-2 range-slider">
                    </div>
                </div>

                <!-- 3. UTILITY CONTROLS CARD -->
                <div class="ui-card p-4 space-y-4">
                    <h2 class="text-xl font-bold border-b border-gray-700 pb-2 flex items-center accent-primary">
                        <span class="material-icons mr-2 text-xl">storage</span> Data Management
                    </h2>
                    <div class="grid grid-cols-2 gap-3">
                         <!-- RTD Recording Button -->
                        <button id="recordButton" onclick="toggleRecording()" class="py-2 bg-gray-700 hover:bg-red-700 transition-all duration-200 text-white font-semibold rounded-lg shadow-inner flex items-center justify-center text-sm disabled:opacity-50" disabled>
                            <span class="material-icons text-xl mr-1" id="recordIcon">videocam_off</span>
                            <span id="recordText">Start RTD Record</span>
                        </button>
                        <!-- Fullscreen Button -->
                        <button id="fullscreenButton" onclick="toggleFullscreen()" class="py-2 bg-gray-700 hover:bg-gray-600 transition-all duration-200 text-white font-semibold rounded-lg shadow-inner flex items-center justify-center text-sm disabled:opacity-50" disabled>
                            <span class="material-icons text-xl mr-1">fullscreen</span>
                            Maximize View
                        </button>
                    </div>
                </div>
            </div>
        </div>
    </div>
    
    <!-- Firebase Initialization Script -->
    <script type="module">
        import { initializeApp } from "https://www.gstatic.com/firebasejs/11.6.1/firebase-app.js";
        import { getAuth, signInAnonymously, signInWithCustomToken, onAuthStateChanged, setPersistence, browserSessionPersistence } from "https://www.gstatic.com/firebasejs/11.6.1/firebase-auth.js";
        import { getFirestore, setLogLevel, doc, setDoc, onSnapshot } from "https://www.gstatic.com/firebasejs/11.6.1/firebase-firestore.js";

        // --- Global Firebase Configuration (MANDATORY) ---
        const appId = typeof __app_id !== 'undefined' ? __app_id : 'default-app-id';
        const firebaseConfig = JSON.parse(typeof __firebase_config !== 'undefined' ? __firebase_config : '{}');
        const initialAuthToken = typeof __initial_auth_token !== 'undefined' ? __initial_auth_token : null;
        
        let app;
        let auth;
        let db;
        let userId = null;

        async function initializeFirebase() {
            if (Object.keys(firebaseConfig).length === 0) {
                console.error("Firebase config is empty. Cannot initialize.");
                return;
            }

            try {
                app = initializeApp(firebaseConfig);
                auth = getAuth(app);
                db = getFirestore(app);
                setLogLevel('error'); 

                await setPersistence(auth, browserSessionPersistence);

                await new Promise((resolve) => {
                    const unsubscribe = onAuthStateChanged(auth, async (user) => {
                        unsubscribe(); 
                        if (user) {
                            userId = user.uid;
                            // --- NEW: Load user preferences once authenticated ---
                            window.loadAndSyncPreferences(userId, db, appId);
                            resolve();
                        } else {
                            try {
                                if (initialAuthToken) {
                                    const userCredential = await signInWithCustomToken(auth, initialAuthToken);
                                    userId = userCredential.user.uid;
                                } else {
                                    const userCredential = await signInAnonymously(auth);
                                    userId = userCredential.user.uid;
                                }
                                // --- NEW: Load user preferences once authenticated ---
                                window.loadAndSyncPreferences(userId, db, appId);
                                resolve();
                            } catch (error) {
                                console.error("Firebase Sign-In Error:", error);
                                // Continue initialization even if sign-in fails
                                resolve();
                            }
                        }
                    });
                });
            } catch (error) {
                console.error("Firebase Initialization Failed:", error);
            }
        }
        
        // Run Firebase initialization
        initializeFirebase();

        // --- NEW: Expose db and auth state to window for the main script ---
        // This is a simple way to pass state between <script type="module"> and <script>
        window.getFirebaseServices = () => ({
            db: db,
            getUserId: () => userId, // Use a function to get the latest value
            appId: appId,
            // --- FIX: Expose Firestore functions to the other script scope ---
            doc: doc,
            setDoc: setDoc,
            onSnapshot: onSnapshot
        });

    </script>
    
    <!-- Application Logic Script -->
    <script>
        // --- DOM Elements ---
        const video = document.getElementById('webcamVideo');
        const canvas = document.getElementById('outputCanvas');
        const ctx = canvas.getContext('2d');
        const startButton = document.getElementById('startButton');
        const stopButton = document.getElementById('stopButton');
        const fullscreenButton = document.getElementById('fullscreenButton');
        const sensitivityInput = document.getElementById('sensitivity');
        const sensitivityValueSpan = document.getElementById('sensitivityValue');
        const recordButton = document.getElementById('recordButton');
        const recordIcon = document.getElementById('recordIcon');
        const recordText = document.getElementById('recordText');
        const aiDetectionToggle = document.getElementById('aiDetectionToggle');
        const aiIcon = document.getElementById('aiIcon');
        const aiText = document.getElementById('aiText');

        // --- NEW Toggles ---
        const modeLiveVideo = document.getElementById('modeLiveVideo');
        const modeDepthMap = document.getElementById('modeDepthMap');
        

        // --- State Variables ---
        let animationFrameId;
        let stream;
        let showProcessedMap = true; // Default to Depth Map
        let edgeSensitivity = 1.5; 
        let detectionModel = null;
        let detections = [];
        let currentDetectionMode = 'V1'; // 'V1', 'V2', 'OFF'
        let detectionInterval = 500; // Default V1
        let detectionThreshold = 0.6; // Default V1
        let lastDetectionTime = 0;
        
        // Recording State
        let isRecording = false;
        let mediaRecorder;
        let recordedChunks = [];
        
        // --- Kernels ---
        const sobelX = [ [-1, 0, 1], [-2, 0, 2], [-1, 0, 1] ];
        const sobelY = [ [-1, -2, -1], [0, 0, 0], [1, 2, 1] ];
        const gaussianKernel = [ [1, 2, 1], [2, 4, 2], [1, 2, 1] ];
        const kernelSum = 16;
        
        // --- Model and Mode Functions ---

        async function loadDetectionModel() {
            console.log('[SYS] Loading ML Module...');
            // --- NEW: Set loading state on button ---
            startButton.disabled = true;
            startButton.innerHTML = `<span class="material-icons text-3xl mr-2 animate-spin">refresh</span> LOADING...`;

            try {
                await tf.ready(); 
                detectionModel = await cocoSsd.load();
                
                // Preferences might be loaded from Firebase *before* this,
                // so we only set default if it's still V1 (or not set)
                if (currentDetectionMode === 'V1') {
                    setDetectionMode('V1');
                }

                console.log('[SYS] Module online. Ready for Power On.');
                // --- NEW: Update button on success ---
                startButton.innerHTML = `<span class="material-icons text-3xl mr-2">camera_indoor</span> POWER ON`;
                startButton.disabled = false;
            } catch (error) {
                console.error("[ERR] Model load failed. Check console.", error);
                // --- NEW: Update button on failure ---
                startButton.innerHTML = `<span class="material-icons text-3xl mr-2">error_outline</span> LOAD FAILED`;
                startButton.classList.add('bg-red-600', 'text-white');
            }
        }
        
        function updateAIDetectionButton(mode) {
            currentDetectionMode = mode;
            aiDetectionToggle.classList.remove('ai-v1', 'ai-v2', 'ai-off');
            aiIcon.classList.remove('text-yellow-400', 'text-primary-cyan', 'text-red-400');
            aiIcon.classList.add('text-white'); // Make icon white/dark depending on background

            let iconText = '';
            let buttonClass = '';

            switch (mode) {
                case 'V1':
                    detectionInterval = 500; 
                    detectionThreshold = 0.6;
                    iconText = 'AI Detection: V1 (Standard)';
                    buttonClass = 'ai-v1';
                    break;
                case 'V2':
                    detectionInterval = 750; 
                    detectionThreshold = 0.8;
                    iconText = 'AI Detection: V2 (Pico-Pro)'; 
                    buttonClass = 'ai-v2'; 
                    break;
                case 'OFF':
                    detectionInterval = Infinity; 
                    detectionThreshold = 1.0;
                    detections = []; 
                    iconText = 'AI Detection: OFF';
                    buttonClass = 'ai-off';
                    break;
            }
            
            aiText.textContent = iconText;
            aiDetectionToggle.classList.add(buttonClass);
            console.log(`[SYS] AI Detection set to ${mode}.`);
            
            // --- NEW: Save preference ---
            saveUserPreferences();
        }

        function setDetectionMode(mode) {
            updateAIDetectionButton(mode);
        }

        window.toggleAIDetectionMode = function() {
            switch (currentDetectionMode) {
                case 'V1':
                    setDetectionMode('V2');
                    break;
                case 'V2':
                    setDetectionMode('OFF');
                    break;
                case 'OFF':
                default:
                    setDetectionMode('V1');
                    break;
            }
        }


        // --- Controls and Interaction Functions ---

        // --- RECoded Fullscreen Feature ---
        window.toggleFullscreen = function() {
            const docEl = document.documentElement;
            const isFullscreen = document.fullscreenElement || document.webkitFullscreenElement || document.msFullscreenElement;

            if (isFullscreen) {
                // Exit fullscreen
                if (document.exitFullscreen) {
                    document.exitFullscreen();
                } else if (document.webkitExitFullscreen) { 
                    document.webkitExitFullscreen();
                } else if (document.msExitFullscreen) { 
                    document.msExitFullscreen();
                }
            } else {
                // Enter fullscreen
                if (docEl.requestFullscreen) {
                    docEl.requestFullscreen();
                } else if (docEl.webkitRequestFullscreen) {
                    docEl.webkitRequestFullscreen();
                } else if (docEl.msRequestFullscreen) {
                    docEl.msRequestFullscreen();
                }
            }
        }

        function handleFullscreenChange() {
            const isFullscreen = document.fullscreenElement || document.webkitFullscreenElement || document.msFullscreenElement;
            const icon = fullscreenButton.querySelector('.material-icons');
            // Check if text node exists (index 2 in childNodes) before accessing
            const textNode = fullscreenButton.childNodes.length > 2 ? fullscreenButton.childNodes[2] : null; 

            if (isFullscreen) {
                icon.textContent = 'fullscreen_exit';
                if (textNode) textNode.textContent = 'Minimize View';
                console.log('[SYS] Fullscreen Engaged. Use ESC key to exit.');
            } else {
                icon.textContent = 'fullscreen';
                if (textNode) textNode.textContent = 'Maximize View';
                console.log('[SYS] Fullscreen Disengaged.');
            }
        }
        document.addEventListener('fullscreenchange', handleFullscreenChange);
        document.addEventListener('webkitfullscreenchange', handleFullscreenChange);
        document.addEventListener('msfullscreenchange', handleFullscreenChange);
        // --- END RECoded Fullscreen Feature ---
        
        window.updateSensitivity = function(value) {
            edgeSensitivity = parseFloat(value);
            sensitivityValueSpan.textContent = edgeSensitivity.toFixed(1) + 'x';
            // --- NEW: Save preference ---
            saveUserPreferences();
        }

        // --- REDESIGNED setMode function ---
        window.setMode = function(showMap) {
            showProcessedMap = showMap;
            
            const activeClass = 'segmented-btn-active';
            const inactiveClass = 'segmented-btn-inactive';

            if (showMap) {
                modeDepthMap.classList.add(activeClass);
                modeDepthMap.classList.remove(inactiveClass);
                modeLiveVideo.classList.add(inactiveClass);
                modeLiveVideo.classList.remove(activeClass);
                console.log('[SYS] Display Mode set to Depth Map (Processed).');
            } else {
                modeLiveVideo.classList.add(activeClass);
                modeLiveVideo.classList.remove(inactiveClass);
                modeDepthMap.classList.add(inactiveClass);
                modeDepthMap.classList.remove(activeClass);
                console.log('[SYS] Display Mode set to Live Video (Raw).');
            }
        }
        
        // --- RTD Recording ---
        
        window.toggleRecording = function() {
            if (isRecording) {
                stopRecording();
            } else {
                startRecording();
            }
        }

        function startRecording() {
            if (!stream || isRecording) return;
            
            isRecording = true;
            recordedChunks = [];

            // Capture the content of the CANVAS (the processed feed)
            const canvasStream = canvas.captureStream(30); 
            mediaRecorder = new MediaRecorder(canvasStream, { mimeType: 'video/webm; codecs=vp8' });

            mediaRecorder.ondataavailable = (event) => {
                if (event.data.size > 0) {
                    recordedChunks.push(event.data);
                }
            };

            mediaRecorder.onstop = () => {
                const blob = new Blob(recordedChunks, { type: 'video/webm' });
                const url = URL.createObjectURL(blob);
                const a = document.createElement('a');
                a.style.display = 'none';
                a.href = url;
                a.download = `DashTrack_RTD_${new Date().toISOString()}.webm`;
                document.body.appendChild(a);
                a.click();
                window.URL.revokeObjectURL(url);
                
                console.log(`[SYS] RTD Recording Saved and Downloaded.`);
            };

            mediaRecorder.start();

            // UI Update
            recordIcon.textContent = 'videocam';
            recordButton.classList.remove('bg-gray-700', 'hover:bg-red-700');
            recordButton.classList.add('bg-red-600', 'hover:bg-red-500', 'active');
            recordText.textContent = 'Stop RTD Record';
            console.log('[SYS] RTD Recording started.');
        }

        function stopRecording() {
            if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                mediaRecorder.stop();
            }
            isRecording = false;

            // UI Update
            recordIcon.textContent = 'videocam_off';
            recordButton.classList.remove('bg-red-600', 'hover:bg-red-500', 'active');
            recordButton.classList.add('bg-gray-700', 'hover:bg-red-700');
            recordText.textContent = 'Start RTD Record';
            console.log('[SYS] RTD Recording finalizing. Preparing download...');
        }
        
        // --- Core Application Logic ---

        window.startCamera = function() {
            if (stream) { stopCamera(); }

            console.log('[SYS] Requesting Stream Access...');
            startButton.disabled = true;

            navigator.mediaDevices.getUserMedia({ 
                video: { 
                    facingMode: 'user',
                    aspectRatio: { ideal: 1.7777 }, 
                    width: { ideal: 1280 },
                    height: { ideal: 720 }
                } 
            })
            .then(mediaStream => {
                stream = mediaStream;
                video.srcObject = stream;
                video.onloadedmetadata = () => {
                    // Set canvas drawing buffer to video resolution
                    canvas.width = video.videoWidth;
                    canvas.height = video.videoHeight;
                    video.play();
                    
                    console.log(`[SYS] Dash.Track Active. Resolution: ${canvas.width}x${canvas.height}.`);
                    stopButton.disabled = false;
                    fullscreenButton.disabled = false;
                    recordButton.disabled = false;
                    aiDetectionToggle.disabled = false; 
                    modeLiveVideo.disabled = false; // Enable new mode buttons
                    modeDepthMap.disabled = false; // Enable new mode buttons
                    
                    requestAnimationFrame(processFrame);
                    // Initial detection run (non-blocking)
                    runObjectDetection(); 
                };
            })
            .catch(err => {
                console.error("[ERR] Access Denied: Check browser permissions.", err);
                startButton.disabled = false;
            });
        }

        window.stopCamera = function() {
            if (animationFrameId) {
                cancelAnimationFrame(animationFrameId);
                animationFrameId = null;
            }
            if (isRecording) {
                stopRecording();
            }
            if (stream) {
                stream.getTracks().forEach(track => track.stop());
                stream = null;
                video.srcObject = null;
            }
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            console.log('[SYS] Power Down Complete. System Offline.');
            
            startButton.disabled = false;
            stopButton.disabled = true;
            fullscreenButton.disabled = true;
            recordButton.disabled = true;
            aiDetectionToggle.disabled = true; 
            modeLiveVideo.disabled = true; // Disable new mode buttons
            modeDepthMap.disabled = true; // Disable new mode buttons

            detections = [];
            
            // Reset state and UI toggles
            window.setMode(true); // Default to Depth Map on reset (UI update handles classes)
        }

        async function runObjectDetection() {
            if (currentDetectionMode === 'OFF' || !detectionModel) {
                detections = [];
                return;
            }
            
            const now = performance.now();
            if (now - lastDetectionTime < detectionInterval) {
                return;
            }
            lastDetectionTime = now;
            
            try {
                const rawDetections = await detectionModel.detect(video);
                detections = rawDetections.filter(p => p.score >= detectionThreshold);
                
            } catch (error) {
                console.error("Detection error:", error);
                detections = [];
            }
        }
        
        function processFrame(time) {
            if (!video.paused && !video.ended) {
                
                ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
                
                if (showProcessedMap) {
                    applyPseudoDepthFilter();
                }

                drawDetections();
            }
            
            runObjectDetection();
            animationFrameId = requestAnimationFrame(processFrame);
        }

        // --- Image Processing Functions ---

        function applyGaussianBlur(grayData, width, height) {
            const blurredData = new Array(width * height).fill(0);
            for (let y = 1; y < height - 1; y++) {
                for (let x = 1; x < width - 1; x++) {
                    let sum = 0;
                    for (let ky = -1; ky <= 1; ky++) {
                        for (let kx = -1; kx <= 1; kx++) {
                            const pixelIndex = (y + ky) * width + (x + kx);
                            const kernelValue = gaussianKernel[ky + 1][kx + 1];
                            sum += grayData[pixelIndex] * kernelValue;
                        }
                    }
                    blurredData[y * width + x] = sum / kernelSum;
                }
            }
            for (let i = 0; i < width; i++) {
                blurredData[i] = grayData[i]; 
                blurredData[(height - 1) * width + i] = grayData[(height - 1) * width + i];
            }
            for (let j = 0; j < height; j++) {
                blurredData[j * width] = grayData[j * width]; 
                blurredData[j * width + width - 1] = grayData[j * width + width - 1];
            }
            return blurredData;
        }

        function applyPseudoDepthFilter() {
            let imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
            let data = imageData.data;
            const width = canvas.width;
            const height = canvas.height;
            
            const grayData = new Array(width * height);

            for (let i = 0; i < data.length; i += 4) {
                let r = data[i];
                let g = data[i + 1];
                let b = data[i + 2];
                
                const gray = 0.2126 * r + 0.7152 * g + 0.0722 * b;
                grayData[i / 4] = gray;
            }

            const blurredGrayData = applyGaussianBlur(grayData, width, height);

            for (let y = 1; y < height - 1; y++) {
                for (let x = 1; x < width - 1; x++) {
                    const i = y * width + x;
                    
                    let Gx = 0;
                    let Gy = 0;

                    for (let ky = -1; ky <= 1; ky++) {
                        for (let kx = -1; kx <= 1; kx++) {
                            const pixelIndex = (y + ky) * width + (x + kx);
                            const kernelXValue = sobelX[ky + 1][kx + 1];
                            const kernelYValue = sobelY[ky + 1][kx + 1];
                            const blurredGrayValue = blurredGrayData[pixelIndex];

                            Gx += blurredGrayValue * kernelXValue;
                            Gy += blurredGrayValue * kernelYValue;
                        }
                    }

                    const magnitude = Math.sqrt(Gx * Gx + Gy * Gy);
                    const edgeStrength = Math.min(255, Math.max(0, magnitude * edgeSensitivity)); 

                    let r, g, b;
                    const t = edgeStrength / 255.0; 

                    // Color mapping: Blue (far/weak edge) to Red (near/strong edge)
                    if (t < 0.5) {
                        r = 0;
                        g = Math.floor(t * 2 * 255);
                        b = Math.floor(255 - t * 2 * 255);
                    } else {
                        r = Math.floor((t - 0.5) * 2 * 255);
                        g = Math.floor(255 - (t - 0.5) * 2 * 255);
                        b = 0;
                    }

                    const dataIndex = i * 4;
                    data[dataIndex] = r;
                    data[dataIndex + 1] = g;
                    data[dataIndex + 2] = b;
                }
            }

            ctx.putImageData(imageData, 0, 0);
        }

        // --- NEW: Firebase Preference Functions ---

        // Function to save preferences to Firestore
        async function saveUserPreferences() {
            // --- FIX: Get all necessary functions from the module script ---
            const { db, getUserId, appId, doc, setDoc } = window.getFirebaseServices();
            const userId = getUserId();
            
            if (!db || !userId) {
                // console.log('[SYS] Cannot save preferences: Firebase not ready or user not logged in.');
                return;
            }

            const prefs = {
                sensitivity: edgeSensitivity,
                detectionMode: currentDetectionMode,
                // Save display mode
                displayMap: showProcessedMap
            };
            
            try {
                // --- FIX: 'doc' and 'setDoc' are now correctly referenced ---
                const prefsDocRef = doc(db, 'artifacts', appId, 'users', userId, 'userPreferences', 'settings');
                await setDoc(prefsDocRef, prefs, { merge: true });
                // console.log('[SYS] User preferences saved to Firestore.');
            } catch (error) {
                console.error('[ERR] Failed to save preferences:', error);
            }
        }

        // Function to load and sync preferences from Firestore
        window.loadAndSyncPreferences = function(userId, db, appId) {
            // --- FIX: Get 'doc' and 'onSnapshot' from the module script ---
            const { doc, onSnapshot } = window.getFirebaseServices();

            if (!db || !userId || !doc || !onSnapshot) {
                console.error('[ERR] Firebase services not ready for preference loading.');
                return;
            }
            
            // --- FIX: 'doc' and 'onSnapshot' are now correctly referenced ---
            const prefsDocRef = doc(db, 'artifacts', appId, 'users', userId, 'userPreferences', 'settings');
            
            onSnapshot(prefsDocRef, (docSnap) => {
                if (docSnap.exists()) {
                    const prefs = docSnap.data();
                    console.log('[SYS] User preferences loaded from Firestore.');

                    if (prefs.sensitivity !== undefined) {
                        edgeSensitivity = parseFloat(prefs.sensitivity);
                        sensitivityInput.value = edgeSensitivity;
                        sensitivityValueSpan.textContent = edgeSensitivity.toFixed(1) + 'x';
                    }
                    if (prefs.detectionMode) {
                        setDetectionMode(prefs.detectionMode);
                    }
                    if (prefs.displayMap !== undefined) {
                        // Use the new setMode function to update the UI correctly
                        window.setMode(prefs.displayMap);
                    }
                } else {
                    console.log('[SYS] No user preferences found. Using default settings.');
                    // Ensure defaults are applied to UI if nothing is found
                    window.setMode(showProcessedMap); // Apply initial JS value (true)
                    updateAIDetectionButton(currentDetectionMode); // Apply initial JS value (V1)
                }
            }, (error) => {
                console.error('[ERR] Failed to load preferences:', error);
            });
        }


        // --- Detection Drawing Functions ---

        function drawRigSkeleton(x, y, width, height) {
            // Rig drawing only for V1
            if (currentDetectionMode !== 'V1') return; 

            // V4.0 Rig Color: Bright Cyan
            ctx.strokeStyle = '#2dd4bf'; 
            ctx.fillStyle = '#67e8f9'; 
            ctx.lineWidth = 3; 
            ctx.shadowBlur = 0; 

            const jointRadius = Math.max(3, Math.min(7, height * 0.007)); 

            const p = (relX, relY) => ({
                x: x + width * relX,
                y: y + height * relY
            });

            const points = {
                nose: p(0.5, 0.05), leftEye: p(0.45, 0.05), rightEye: p(0.55, 0.05),
                leftEar: p(0.35, 0.1), rightEar: p(0.65, 0.1),
                leftShoulder: p(0.3, 0.25), rightShoulder: p(0.7, 0.25),
                leftHip: p(0.4, 0.6), rightHip: p(0.6, 0.6),
                leftElbow: p(0.2, 0.45), rightElbow: p(0.8, 0.45),
                leftWrist: p(0.1, 0.7), rightWrist: p(0.9, 0.7),
                leftKnee: p(0.4, 0.8), rightKnee: p(0.6, 0.8),
                leftAnkle: p(0.4, 0.95), rightAnkle: p(0.6, 0.95),
            };

            const connections = [
                [points.leftEye, points.nose], [points.rightEye, points.nose],
                [points.leftEar, points.leftShoulder], [points.rightEar, points.rightShoulder],
                [points.leftShoulder, points.rightShoulder], [points.leftShoulder, points.leftHip],
                [points.rightShoulder, points.rightHip], [points.leftHip, points.rightHip],
                [points.leftShoulder, points.leftElbow], [points.leftElbow, points.leftWrist],
                [points.rightShoulder, points.rightElbow], [points.rightElbow, points.rightWrist],
                [points.leftHip, points.leftKnee], [points.leftKnee, points.leftAnkle],
                [points.rightHip, points.rightKnee], [points.rightKnee, points.rightAnkle],
            ];
            
            ctx.beginPath();
            connections.forEach(([p1, p2]) => { ctx.moveTo(p1.x, p1.y); ctx.lineTo(p2.x, p2.y); });
            ctx.stroke();

            Object.values(points).forEach(p => {
                ctx.beginPath();
                ctx.arc(p.x, p.y, jointRadius, 0, 2 * Math.PI);
                ctx.fill();
            });
        }


        function drawDetections() {
            ctx.lineWidth = 2;
            ctx.font = '14px Inter, sans-serif';
            ctx.shadowBlur = 5;

            detections.forEach(prediction => {
                const [x, y, width, height] = prediction.bbox;
                const score = (prediction.score * 100).toFixed(1);
                const label = `${prediction.class} (${score}%)`;
                
                let boxColor;

                if (prediction.class === 'person') {
                    // V2 gets the primary-cyan color (Pico-Pro, high precision, no rig)
                    boxColor = currentDetectionMode === 'V2' ? '#2dd4bf' : '#fcd34d'; // V1 is yellow
                    
                    if (currentDetectionMode === 'V1') {
                        drawRigSkeleton(x, y, width, height); 
                    }

                } else if (prediction.class === 'cell phone' || prediction.class === 'laptop') {
                    boxColor = '#f59e0b'; // Amber for devices
                } else {
                    boxColor = '#a78bfa'; // Violet for general objects
                }
                
                ctx.strokeStyle = boxColor; 
                ctx.fillStyle = boxColor;
                
                ctx.shadowColor = boxColor; 
                ctx.strokeRect(x, y, width, height);

                const textWidth = ctx.measureText(label).width;
                const textHeight = 18; 
                
                // Draw opaque background for label
                ctx.save();
                ctx.fillStyle = boxColor;
                ctx.fillRect(x, y, textWidth + 10, textHeight + 4);
                ctx.restore();

                // Draw Label Text
                ctx.fillStyle = '#0d1117'; // Text inside label box is dark
                ctx.shadowBlur = 0;
                ctx.fillText(label, x + 5, y + textHeight - 2);
            });
        }

        // Initial setup
        document.addEventListener('DOMContentLoaded', () => {
            loadDetectionModel();
            updateSensitivity(sensitivityInput.value);
            window.addEventListener('beforeunload', stopCamera);
            
            // Set initial state for the new mode buttons (which will be overwritten by Firebase if available)
            window.setMode(showProcessedMap);
            updateAIDetectionButton(currentDetectionMode);
        });

    </script>
</body>
</html>
